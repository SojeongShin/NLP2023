{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SojeongShin/NLP_2023/blob/Notion/2_2_%E1%84%8F%E1%85%A1%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%90%E1%85%B3_%E1%84%80%E1%85%B5%E1%84%87%E1%85%A1%E1%86%AB%E1%84%8B%E1%85%B4_%E1%84%86%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%84%91%E1%85%AD%E1%84%92%E1%85%A7%E1%86%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MBZ_OvZQPIU"
      },
      "source": [
        "# 2주차(2-2). 카운트 기반의 문서표현\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*이탤릭체 텍스트*# 202001581 신소정"
      ],
      "metadata": {
        "id": "P6UkURyzom6Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HEzTD_eQPIW"
      },
      "source": [
        "## 1. BOW 기반의 카운트 벡터 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhO1nZs3QPIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10127628-722d-46b4-86ed-5c408622c3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j4tX9_WvQPIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be59da99-da52-4c8d-9f91-61e1299f28b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#review count: 2000\n",
            "#samples of file ids: ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n",
            "#categories of reviews: ['neg', 'pos']\n",
            "#num of \"neg\" reviews: 1000\n",
            "#num of \"pos\" reviews: 1000\n",
            "#id of the first review: neg/cv000_29416.txt\n",
            "#first review content:\n",
            " plot : two teen couples go to a church party , drink and then drive . \n",
            "they get into an accident . \n",
            "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
            "w\n",
            "\n",
            "#sentence tokenization result: ['plot : two teen couples go to a church party , drink and then drive .', 'they get into an accident .']\n",
            "#word tokenization result: ['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "print('#review count:', len(movie_reviews.fileids())) #영화 리뷰 문서의 id를 반환\n",
        "print('#samples of file ids:', movie_reviews.fileids()[:10]) #id를 10개까지만 출력\n",
        "print('#categories of reviews:', movie_reviews.categories()) # label, 즉 긍정인지 부정인지에 대한 분류\n",
        "print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) #label이 부정인 문서들의 id를 반환\n",
        "print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) #label이 긍정인 문서들의 id를 반환\n",
        "fileid = movie_reviews.fileids()[0] #첫번째 문서의 id를 반환\n",
        "print('#id of the first review:', fileid)\n",
        "print('#first review content:\\n', movie_reviews.raw(fileid)[:200]) #첫번째 문서의 내용을 200자까지만 출력\n",
        "print()\n",
        "print('#sentence tokenization result:', sent_tokenize(movie_reviews.raw(fileid))[:2]) #첫번째 문서를 sentence tokenize한 결과 중 앞 두 문장\n",
        "print('#word tokenization result:', word_tokenize(movie_reviews.raw(fileid))[:20]) #첫번째 문서를 word tokenize한 결과 중 앞 스무 단어"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FKyZJRiVQPIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85b6fba-da5c-4eab-8e0f-b5f44fbd43a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'s\", 'the', 'deal', '?', 'watch', 'the']\n"
          ]
        }
      ],
      "source": [
        "documents = [word_tokenize(movie_reviews.raw(fileid)) for fileid in movie_reviews.fileids()]\n",
        "print(documents[0][:50]) #첫째 문서의 앞 50개 단어를 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dnh2dLOoQPIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337df212-067e-40b8-d235-bd8152d265ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count of ',': 77717, count of 'the': 76276, count of '.': 65876, count of 'a': 37995, count of 'and': 35404, count of 'of': 33972, count of 'to': 31772, count of 'is': 26054, count of 'in': 21611, count of ''s': 18128, "
          ]
        }
      ],
      "source": [
        "word_count = {}\n",
        "for text in documents:\n",
        "    for word in text:\n",
        "        word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "sorted_features = sorted(word_count, key=word_count.get, reverse=True)\n",
        "for word in sorted_features[:10]:\n",
        "    print(f\"count of '{word}': {word_count[word]}\", end=', ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 원문을 가져와서 영어의 불용어가 아니고 길이가 3이상인 단어를 토큰화하여 word_count에 빈도수와 단어를 함께 저장하여 정렬한다."
      ],
      "metadata": {
        "id": "sKZZyHqETGir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VnCiEteiQPIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5d1c90-60b9-466a-9f0c-351715ebe5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of features: 45953\n",
            "count of 'film': 9443, count of 'n't': 6217, count of 'movie': 5671, count of 'one': 5582, count of 'like': 3547, count of 'even': 2556, count of 'good': 2316, count of 'time': 2282, count of 'would': 2264, count of 'story': 2146, "
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords #일반적으로 분석대상이 아닌 단어들\n",
        "\n",
        "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
        "\n",
        "#words() 대신 raw()를 이용해 원문을 가져옴\n",
        "documents = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
        "\n",
        "# stopwords의 적용과 토큰화를 동시에 수행.\n",
        "tokens = [[token for token in word_tokenize(doc) if token not in english_stops and len(token) > 2] for doc in documents]\n",
        "\n",
        "word_count = {}\n",
        "for text in tokens:\n",
        "    for word in text:\n",
        "        word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "sorted_features = sorted(word_count, key=word_count.get, reverse=True)\n",
        "\n",
        "print('num of features:', len(sorted_features))\n",
        "for word in sorted_features[:10]:\n",
        "    print(f\"count of '{word}': {word_count[word]}\", end=', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oJSgSJL6QPIZ"
      },
      "outputs": [],
      "source": [
        "word_features = sorted_features[:1000] #빈도가 높은 상위 1000개의 단어만 추출하여 features를 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "document_festures(document, word_features) 함수를 정의한다.\n",
        "document에 있는 단어들의 빈도수를 계산하여 word_count에 저장하고, 각각의 단어에 대한 빈도수를 features애 저장한다. features를 리스트로 반환한다."
      ],
      "metadata": {
        "id": "AJImt-pbSNXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0hXwhgZSQPIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0508c301-f9d3-48c3-a1e6-754753924423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 0, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "def document_features(document, word_features):\n",
        "    word_count = {}\n",
        "    for word in document: #document에 있는 단어들에 대해 빈도수를 먼저 계산\n",
        "        word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "    features = []\n",
        "    for word in word_features: #word_features의 단어에 대해 계산된 빈도수를 feature에 추가\n",
        "        features.append(word_count.get(word, 0)) #빈도가 없는 단어는 0을 입력\n",
        "    return features\n",
        "\n",
        "word_features_ex = ['one', 'two', 'teen', 'couples', 'solo']\n",
        "doc_ex = ['two', 'two', 'couples']\n",
        "print(document_features(doc_ex, word_features_ex))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰에 있는 fetures의 빈도 수를 단어와 함께 데이터 셋으로 만든다."
      ],
      "metadata": {
        "id": "1_Z_cfFrSMX3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y20O-ylCQPIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13d7f94-df32-422d-ea73-2fa3488fd1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(film, 6), (n't, 6), (movie, 6), (one, 3), (like, 3), (even, 3), (good, 2), (time, 0), (would, 1), (story, 0), (much, 0), (character, 2), (also, 1), (get, 3), (characters, 1), (two, 2), (first, 0), (see, 2), (way, 2), (well, 1), "
          ]
        }
      ],
      "source": [
        "feature_sets = [document_features(d, word_features) for d in tokens]\n",
        "\n",
        "# 첫째 feature set의 내용을 앞 20개만 word_features의 단어와 함께 출력\n",
        "for i in range(20):\n",
        "    print(f'({word_features[i]}, {feature_sets[0][i]})', end=', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "roqy5JoaQPIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a828f014-d65f-49df-f551-d72e3443cce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(feature_sets[0][-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zNZ_IBNQPIa"
      },
      "source": [
        "## 2. 사이킷런을 이용한 카운트 벡터 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80KdYKyrQPIa"
      },
      "source": [
        "### CountVectorizer\n",
        "\n",
        "http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6zgO2b5bQPIa"
      },
      "outputs": [],
      "source": [
        "# data 준비, movie_reviews.raw()를 사용하여 raw text를 추출\n",
        "reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mVYPeCi8QPIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2369c3bf-1097-4e92-eddb-37d5dc4f56d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer(max_features=1000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer() #모든 매개변수에 디폴트 값을 사용하는 경우\n",
        "\n",
        "#앞에서 생성한 word_features를 이용하여 특성 집합을 지정하는 경우\n",
        "#cv = CountVectorizer(vocabulary=word_features)\n",
        "\n",
        "cv = CountVectorizer(max_features=1000) #특성 집합을 지정하지 않고 최대 특성의 수를 지정하는 경우\n",
        "print(cv) #객체에 사용된 인수들을 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qsVdPQQYQPIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e08c132-5355-4751-90d3-2c38b1534aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10' 'ability' 'able' 'about' 'above' 'absolutely' 'across' 'act'\n",
            " 'acting' 'action' 'actor' 'actors' 'actress' 'actual' 'actually' 'add'\n",
            " 'after' 'again' 'against' 'age']\n",
            "['film', \"n't\", 'movie', 'one', 'like', 'even', 'good', 'time', 'would', 'story', 'much', 'character', 'also', 'get', 'characters', 'two', 'first', 'see', 'way', 'well']\n"
          ]
        }
      ],
      "source": [
        "reviews_cv = cv.fit_transform(reviews) #reviews를 이용하여 count vector를 학습하고, 변환\n",
        "print(cv.get_feature_names_out()[:20]) # count vector에 사용된 feature 이름을 반환\n",
        "print(word_features[:20]) # 비교를 위해 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "p_V124NBQPIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1e0eb9-671b-459a-870e-3cc920d590b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#type of count vectors: <class 'scipy.sparse._csr.csr_matrix'>\n",
            "#shape of count vectors: (2000, 1000)\n",
            "#sample of count vector:\n",
            "  (0, 3)\t2\n",
            "  (0, 0)\t10\n"
          ]
        }
      ],
      "source": [
        "print('#type of count vectors:', type(reviews_cv))\n",
        "print('#shape of count vectors:', reviews_cv.shape)\n",
        "print('#sample of count vector:')\n",
        "print(reviews_cv[0, :10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sMimZoNDQPIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30725347-7c78-4358-d1f9-f92e0537fbcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2000x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 373712 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "reviews_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1hHNMbBFQPIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4b27bb-fba7-4615-e318-4acc9196671e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10:10, ability:0, able:0, about:2, above:0, absolutely:0, across:0, act:0, acting:0, action:0, actor:0, actors:1, actress:0, actual:0, actually:2, add:0, after:2, again:2, against:0, age:0, "
          ]
        }
      ],
      "source": [
        "for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n",
        "    print(f'{word}:{count}', end=', ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "7KcGBvN9oumi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [[실습 2-2-1]] 마크다운 텍스트 추가하기\n",
        "## 코드 셀 위에 이를 설명하는 마크다운 텍스트를 3개 이상 추가하시오. (포매팅을 하지는 않아도 됨)\n",
        "* 코드 작동에 대한 설명 혹은 코드 결과에 대한 설명 등\n",
        "\n",
        "예시)"
      ],
      "metadata": {
        "id": "tpqUSrtNSwF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 특성의 값을 단어와 함께 보고 싶다면,"
      ],
      "metadata": {
        "id": "2A513CVkohVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n",
        "    print(f'{word}:{count}', end=', ')"
      ],
      "metadata": {
        "id": "B-RGGdavoXLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b9fb33-b051-4cfa-94a0-a0cfc643f3a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "film:6, n't:0, movie:6, one:3, like:3, even:3, good:2, time:0, would:1, story:0, much:0, character:2, also:1, get:3, characters:1, two:2, first:0, see:2, way:3, well:1, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0번째 문서에 대해 20번째 feature 까지의 값을 살펴보았다.\n",
        "* film은 6번 등장하였고, n't는 0번 등장하였다. 이처럼 feature로 사용된 단어가 몇 번 등장했는지 횟수가 담긴 matrix가 만들어졌음을 알 수 있다."
      ],
      "metadata": {
        "id": "4zQP0Wxwpcep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "edkHQ0h1_uwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [[실습 2-2-2]] CountVectorizer() 활용하기\n",
        "\n",
        "\n",
        "```\n",
        "cv = CountVectorizer(vocabulary=word_features)\n",
        "```\n",
        "부분을 주석처리하고,\n",
        "\n",
        "```\n",
        "cv = CountVectorizer(max_features=1000)\n",
        "```\n",
        "주석처리를 해제하여 실행한 후\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n",
        "    print(f'{word}:{count}', end=', ')\n",
        "```\n",
        "의 결과 비교해보기\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q9xsMAmu_00Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 최종적으로 배열의 앞에서부터 총 20개의 데이터를 출력한다고 할 때,\n",
        "\n",
        "cv = CountVectorizer(vocabulary=word_features) 이용\n",
        "-> word_features를 이용하여 특성 집합을 지정하는 경우로 사용자가 설정한 feature가 사용된 단어들의 빈도수가 담긴 배열을 얻을 수 있다.\n",
        "결과 -> film:6, n't:0, movie:6, one:3, like:3, even:3, good:2, time:0, would:1, story:0, much:0, character:2, also:1, get:3, characters:1, two:2, first:0, see:2, way:3, well:1,\n",
        "\n",
        "\n",
        "cv = CountVectorizer(max_features=1000) 이용\n",
        "-> 단어의 특성 집합이 아닌 추출할 최대 특성 개수를 설정하므로, 설정되어 있는 단어들이 차례대로 추출하기에 앞쪽에 원하는 특성을 가진 데이터의 개수가 확인 될 확률이 매우 적다. 다만, 전체 데이터를 추출하고자 한다면 뒤에 원하는 데이터의 개수가 출력될 뿐 확인 가능하다.\n",
        "결과 -> 10:10, ability:0, able:0, about:2, above:0, absolutely:0, across:0, act:0, acting:0, action:0, actor:0, actors:1, actress:0, actual:0, actually:2, add:0, after:2, again:2, against:0, age:0,\n",
        "\n"
      ],
      "metadata": {
        "id": "jMZ1i96KPEmR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}