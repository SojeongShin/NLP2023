{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SojeongShin/NLP_2023/blob/Notion/7_1_%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%AF%E1%86%AB_%E1%84%8E%E1%85%AE%E1%86%A8%E1%84%89%E1%85%A9_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thm_ZG0WcTpC"
      },
      "source": [
        "# [자연어처리]\n",
        "# 7주차(7-1). 차원 축소(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 202001581 신소정 <- 본인의 학번, 이름으로 변경하여 제출\n",
        "* **모든 셀 실행** 후 제출하시기 바랍니다.\n",
        "* **실습 (7-1-1)**이 있습니다. (제출 기한: 10/17(화) 23시 59분까지)"
      ],
      "metadata": {
        "id": "EQjjg1vRuQiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이제 Colab 사용에 모든 수강생분들이 어느정도 익숙해 졌을 거라 생각됩니다!\n",
        "> ##### 중간 중간 **'### ... 이 부분을 완성하시오'** 라는 부분의 코드를 완성해야 합니다.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s7WXGR9ouSPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "946IVH10vEC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6주차 수업 내용 리뷰 -시작-"
      ],
      "metadata": {
        "id": "Kd6v5oMZuT8u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNgIfKg8zWcL"
      },
      "source": [
        "## 6.2 PCA를 이용한 차원 축소\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 셋 준비 (우리에게 익숙한 20newsgroups)"
      ],
      "metadata": {
        "id": "gCb5DPXUGaak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWco5iOPzWcM"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "#20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
        "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "\n",
        "#학습 데이터셋을 가져옴\n",
        "#메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),\n",
        "                                      categories=categories)\n",
        "#검증 데이터셋을 가져옴\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',\n",
        "                                     remove=('headers', 'footers', 'quotes'),\n",
        "                                     categories=categories)\n",
        "\n",
        "X_train = newsgroups_train.data   #학습 데이터셋\n",
        "y_train = newsgroups_train.target #학습 데이터셋\n",
        "\n",
        "X_test = newsgroups_test.data     #검증 데이터셋\n",
        "y_test = newsgroups_test.target   #검증 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리\n",
        "* 토큰화, 불용어처리, 스테밍\n"
      ],
      "metadata": {
        "id": "d03KqvJwGe_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "RJKk1hCjGYwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b15d21-7ab3-4355-babb-434758182d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
        "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
        "stemmer = PorterStemmer() # 스테머로 포터스테머 사용\n",
        "\n",
        "def my_tokenizer(text):\n",
        "    tokens = RegTok.tokenize(text)\n",
        "    # stopwords 제외\n",
        "    words = [word for word in tokens if word not in english_stops]\n",
        "    # portr stemmer 적용\n",
        "    features = [stemmer.stem(token) for token in words]\n",
        "    return features"
      ],
      "metadata": {
        "id": "SmkiLmtOGUEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 약간의 시간(약 30초)이 소요됩니다.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#tfidf = TfidfVectorizer(tokenizer=my_tokenizer, max_features=2000, min_df=5, max_df=0.5)\n",
        "# 토큰화 외에 아무것도 적용하지 않은 채로 확인\n",
        "tfidf = TfidfVectorizer(tokenizer=my_tokenizer) ### ... 이 부분을 완성하시오\n",
        "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
        "X_test_tfidf = tfidf.transform(X_test) # test set을 변환"
      ],
      "metadata": {
        "id": "vwcetq65SOa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73a53ea-5613-4889-94ab-30ecfc8affbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original tfidf matrix shape:', X_train_tfidf.shape)"
      ],
      "metadata": {
        "id": "62cFIpxfIwO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f46336f-4b41-4607-d1d4-375451cc94bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tfidf matrix shape: (2034, 20085)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C-uLYPbzWcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85ef3b3-ac33-47e7-9d79-2565866a47da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tfidf matrix shape: (2034, 20085)\n",
            "PCA Converted matrix shape: (2034, 2000)\n",
            "Sum of explained variance ratio: 1.000\n"
          ]
        }
      ],
      "source": [
        "# 약간의 시간(약 30초)이 소요됩니다.\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#  20,085 차원을 2,000 차원으로 축소\n",
        "pca = PCA(n_components=2000, random_state=7) ### ... 이 부분을 완성하시오\n",
        "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
        "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
        "\n",
        "print('Original tfidf matrix shape:', X_train_tfidf.shape)\n",
        "print('PCA Converted matrix shape:', X_train_pca.shape)\n",
        "print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oW4iq1IzWcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cc2f3d-9300-4425-a763-a8ec89b9648c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set score: 0.962\n",
            "#Test set score: 0.761\n",
            "#Train set score: 0.962\n",
            "#Test set score: 0.761\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR_clf = LogisticRegression() #분류기 선언\n",
        "\n",
        "# PCA로 차원 축소된 X 데이터 이용\n",
        "LR_clf.fit(X_train_tfidf, y_train)\n",
        "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "# PCA로 차원 축소된 X 데이터 이용\n",
        "LR_clf.fit(X_train_pca, y_train) ### ... 이 부분을 완성하시오\n",
        "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6주차 수업 내용 리뷰 -끝-"
      ],
      "metadata": {
        "id": "uu0mgpF6uUnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "G5Hw9SDwvFLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-1 주차 수업 내용 -시작-\n",
        "\n"
      ],
      "metadata": {
        "id": "uPBwVvw2u0x9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atiT2bq8cTpJ"
      },
      "source": [
        "## 6.3 LSA를 이용한 차원 축소와 의미 파악\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 기존의 DTM이나 DTM에 단어의 중요도에 따른 가중치를 주었던 TF-IDF 행렬은 단어의 의미를 전혀 고려하지 못한다는 단점을 갖고 있었습니다.\n",
        "* LSA는 기본적으로 DTM이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다는 아이디어를 갖고 있습니다."
      ],
      "metadata": {
        "id": "s97_V7Wo1tUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DTM"
      ],
      "metadata": {
        "id": "rdpt3zejjxi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    '먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요'\n",
        "]\n",
        "\n",
        "# 각 문서를 공백 기준으로 단어로 분리\n",
        "tokenized_corpus = [doc.split() for doc in corpus]\n",
        "print(tokenized_corpus)"
      ],
      "metadata": {
        "id": "RHXTzFRDjw-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9903c5da-19ce-4615-b0d7-fefc29ec7e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['먹고', '싶은', '사과'], ['먹고', '싶은', '바나나'], ['길고', '노란', '바나나', '바나나'], ['저는', '과일이', '좋아요']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 단어들의 집합 생성 후 가나다 순으로 정렬\n",
        "vocabulary = sorted(set(word for doc in tokenized_corpus for word in doc))\n",
        "print(vocabulary)\n",
        "\n",
        "# 단어와 인덱스를 맵핑한 딕셔너리 생성\n",
        "word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "print(word2idx)"
      ],
      "metadata": {
        "id": "OixVAbctknEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2546b0-04df-4877-eac8-3c07cfbb0d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']\n",
            "{'과일이': 0, '길고': 1, '노란': 2, '먹고': 3, '바나나': 4, '사과': 5, '싶은': 6, '저는': 7, '좋아요': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도수 계산\n",
        "word_frequency = []\n",
        "for doc in tokenized_corpus:\n",
        "    frequency = [0] * len(vocabulary)\n",
        "    for word in doc:\n",
        "        if word in word2idx:\n",
        "            frequency[word2idx[word]] += 1\n",
        "    word_frequency.append(frequency)\n",
        "\n",
        "for freq in word_frequency:\n",
        "    print(freq)"
      ],
      "metadata": {
        "id": "erc4tt4wknG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdc67d8-3266-40fb-c0a0-9ef0feed6b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "[0, 1, 1, 0, 2, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn의 CountVectorizer를 이용한 DTM"
      ],
      "metadata": {
        "id": "xuACOS6ylHVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "    '먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요'\n",
        "]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "\n",
        "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "A = vector.fit_transform(corpus).toarray()\n",
        "\n",
        "# 각 단어와 맵핑된 인덱스 출력\n",
        "print(vector.vocabulary_)\n",
        "print(A)\n",
        "print(A.shape)"
      ],
      "metadata": {
        "id": "U4Wy2HV4zaeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ebf176-3a2d-45d5-8c81-c2c392b9adfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'먹고': 3, '싶은': 6, '사과': 5, '바나나': 4, '길고': 1, '노란': 2, '저는': 7, '과일이': 0, '좋아요': 8}\n",
            "[[0 0 0 1 0 1 1 0 0]\n",
            " [0 0 0 1 1 0 1 0 0]\n",
            " [0 1 1 0 2 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 1 1]]\n",
            "(4, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full SVD"
      ],
      "metadata": {
        "id": "H9byyZNe0hTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4 × 9의 크기를 가지는 DTM이 생성되었습니다.-> 4개의 문서, 9개의 단어\n",
        "\n",
        "* 이에 대해서 풀 SVD(full SVD)를 수행해보겠습니다.\n",
        "    * 단, 여기서는 대각 행렬의 변수명을 Σ가 아니라 S를 사용합니다.\n",
        "    * 또한 V의 전치 행렬을 VT라고 하겠습니다.\n",
        "    * 소수점의 길이가 너무 길게 출력하면 보기 힘들어서 두번째 자리까지만 출력하기위해서 .round(2)를 사용합니다."
      ],
      "metadata": {
        "id": "gDutZy3u1ZZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "U, s, VT = np.linalg.svd(A, full_matrices = True)"
      ],
      "metadata": {
        "id": "43wXmxxez7Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('행렬 U :')\n",
        "print(U.round(2))\n",
        "print('행렬 U의 크기(shape) :',np.shape(U))"
      ],
      "metadata": {
        "id": "6r2rt5wI0Q2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d4e3ce-4ccf-4097-b766-05f731aa40c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "행렬 U :\n",
            "[[-0.24  0.75  0.   -0.62]\n",
            " [-0.51  0.44 -0.    0.74]\n",
            " [-0.83 -0.49 -0.   -0.27]\n",
            " [-0.   -0.    1.    0.  ]]\n",
            "행렬 U의 크기(shape) : (4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4 × 4의 크기를 가지는 직교 행렬 U가 생성되었습니다.\n",
        "* 이제 대각 행렬 S를 확인해봅시다."
      ],
      "metadata": {
        "id": "T6DdED2q1WHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('특이값 벡터 :')\n",
        "print(s.round(2))\n",
        "print('특이값 벡터의 크기(shape) :',np.shape(s))"
      ],
      "metadata": {
        "id": "whwmlvcy0TwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810af6a7-8d62-4821-aacf-8555a30f7cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "특이값 벡터 :\n",
            "[2.69 2.05 1.73 0.77]\n",
            "특이값 벡터의 크기(shape) : (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Numpy의 linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환합니다.\n",
        "* 그러므로 앞서 본 수식의 형식으로 보려면 이를 다시 대각 행렬로 바꾸어 주어야 합니다.\n",
        "* 우선 특이값을 s에 저장하고 대각 행렬 크기의 행렬을 생성한 후에 그 행렬에 특이값을 삽입해도록 하겠습니다."
      ],
      "metadata": {
        "id": "-LjiVpLw1hu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성 <- 원래 벡터로 복원하는 과정\n",
        "S = np.zeros((4, 9))\n",
        "\n",
        "# 특이값을 대각행렬에 삽입\n",
        "S[:4, :4] = np.diag(s)\n",
        "\n",
        "print('대각 행렬 S :')\n",
        "print(S.round(2))\n",
        "\n",
        "print('대각 행렬의 크기(shape) :')\n",
        "print(np.shape(S))"
      ],
      "metadata": {
        "id": "qqP6HS_U1EPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec60c0a0-c120-49eb-8f11-dbbed7172388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "대각 행렬 S :\n",
            "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n",
            "대각 행렬의 크기(shape) :\n",
            "(4, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4 × 9의 크기를 가지는 대각 행렬 S가 생성되었습니다.\n",
        "* 2.69 > 2.05 > 1.73 > 0.77 순으로 값이 내림차순을 보이는 것을 확인할 수 있습니다.\n",
        "* 정보량이 클수록 첫번째 벡터, 숫자가 크다."
      ],
      "metadata": {
        "id": "w283FcEC1kv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('직교행렬 VT :')\n",
        "print(VT.round(2))\n",
        "\n",
        "print('직교 행렬 VT의 크기(shape) :')\n",
        "print(np.shape(VT))"
      ],
      "metadata": {
        "id": "jusQppK20TzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4699e25-e240-4ffd-f30f-d1184926bf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "직교행렬 VT :\n",
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
            " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
            " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
            " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
            " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
            " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n",
            "직교 행렬 VT의 크기(shape) :\n",
            "(9, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 9 × 9의 크기를 가지는 직교 행렬 VT(V의 전치 행렬)가 생성되었습니다.\n",
        "<br><br>\n",
        "* 이제 U × S × VT를 하면 기존의 행렬 A가 나와야 합니다.\n",
        "* Numpy의 allclose()는 2개의 행렬이 동일하면 True를 리턴합니다.\n",
        "    * 이를 사용하여 정말로 기존의 행렬 A와 동일한지 확인해보겠습니다."
      ],
      "metadata": {
        "id": "JLvFbEDr1nNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
      ],
      "metadata": {
        "id": "avhJ-UFX1Lgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb08655a-ce1c-423a-a597-7092d9bb9942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Truncated SVD"
      ],
      "metadata": {
        "id": "XBJGXTBT0j4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 지금까지 수행한 것은 풀 SVD(Full SVD)입니다.\n",
        "* 이제 t를 정하고, 절단된 SVD(Truncated SVD)를 수행해보도록 합시다. 여기서는 t=2로 하겠습니다.\n",
        "* 우선 대각 행렬 S 내의 특이값 중에서 상위 2개만 남기고 제거해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "bMfX9jr31poZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특이값 상위 2개만 보존\n",
        "S = S[:2,:2] ### ... 이 부분을 완성하시오\n",
        "\n",
        "print('대각 행렬 S :')\n",
        "print(S.round(2))"
      ],
      "metadata": {
        "id": "fsPgkMFr0dSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f3be63-c090-43a6-bbb5-4a4aa71efa37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "대각 행렬 S :\n",
            "[[2.69 0.  ]\n",
            " [0.   2.05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 상위 2개의 값만 남기고 나머지는 모두 제거된 것을 볼 수 있습니다.\n",
        "* 이제 직교 행렬 U에 대해서도 2개의 열만 남기고 제거합니다."
      ],
      "metadata": {
        "id": "Oj926yZ81zDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "U = U[:,:2] ### ... 이 부분을 완성하시오\n",
        "print('행렬 U :')\n",
        "print(U.round(2))"
      ],
      "metadata": {
        "id": "4GhPADcY0T2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b307d11b-eb62-4e56-875e-2632aeb4defb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "행렬 U :\n",
            "[[-0.24  0.75]\n",
            " [-0.51  0.44]\n",
            " [-0.83 -0.49]\n",
            " [-0.   -0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2개의 열만 남기고 모두 제거가 된 것을 볼 수 있습니다.\n",
        "* 이제 행렬 V의 전치 행렬인 VT에 대해서 2개의 행만 남기고 제거합니다.\n",
        "* 이는 V관점에서는 2개의 열만 남기고 제거한 것이 됩니다."
      ],
      "metadata": {
        "id": "hWA3Svrj14Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VT = VT[:2,:] ### ... 이 부분을 완성하시오\n",
        "print('직교행렬 VT :')\n",
        "print(VT.round(2))"
      ],
      "metadata": {
        "id": "Rd0YmBzw11ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776ddef4-f610-4f0c-e8fd-2683b15e05a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "직교행렬 VT :\n",
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이제 축소된 행렬 U, S, VT에 대해서 다시 U × S × VT연산을 하면 기존의 A와는 다른 결과가 나오게 됩니다.\n",
        "* 값이 손실되었기 때문에 이 세 개의 행렬로는 이제 기존의 A행렬을 복구할 수 없습니다.\n",
        "* U × S × VT연산을 해서 나오는 값을 A_prime이라 하고 기존의 행렬 A와 값을 비교해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "YusnY5yl18FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_prime = np.dot(np.dot(U,S), VT)\n",
        "print(A)\n",
        "print(A_prime.round(2))"
      ],
      "metadata": {
        "id": "oB2_R_ir112h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38128ee2-325d-4ffb-f4a0-89254700440e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 1 0 1 1 0 0]\n",
            " [0 0 0 1 1 0 1 0 0]\n",
            " [0 1 1 0 2 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 1 1]]\n",
            "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
            " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
            " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 대체적으로 기존에 0인 값들은 0에 가가운 값이 나오고, 1인 값들은 1에 가까운 값이 나오는 것을 볼 수 있습니다.\n",
        "* 또한 값이 제대로 복구되지 않은 구간도 존재해보입니다.\n",
        "<br>"
      ],
      "metadata": {
        "id": "5XTUfzsx2ABh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [차원 축소된 U, S, VT의 크기의 의미]\n",
        "* 축소된 U는 4 × 2의 크기를 가지는데, 이는 잘 생각해보면 문서의 개수 × 토픽의 수 t의 크기입니다.\n",
        "    * 단어의 개수인 9는 유지되지 않는데 문서의 개수인 4의 크기가 유지되었으니 4개의 문서 각각을 2개의 값으로 표현하고 있습니다.\n",
        "    * 즉, U의 각 행은 잠재 의미를 표현하기 위한 수치화 된 각각의 문서 벡터라고 볼 수 있습니다.\n",
        "* 축소된 VT는 2 × 9의 크기를 가지는데, 이는 잘 생각해보면 토픽의 수 t × 단어의 개수의 크기입니다.\n",
        "    * VT의 각 열은 잠재 의미를 표현하기 위해 수치화된 각각의 단어 벡터라고 볼 수 있습니다.\n",
        "<br>\n",
        "\n",
        "이 문서 벡터들과 단어 벡터들을 통해 다른 문서의 유사도, 다른 단어의 유사도, 단어(쿼리)로부터 문서의 유사도를 구하는 것들이 가능해집니다."
      ],
      "metadata": {
        "id": "1-TlsOCb3vyO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47RWIj59cTpJ"
      },
      "source": [
        "### 6.3.1 LSA를 이용한 차원 축소와 성능\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdSq-LbncTpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a0015d-19f2-414d-e4a7-c9d438e40750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA Converted X shape: (2034, 2000)\n",
            "Sum of explained variance ratio: 1.000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=2000, random_state=7) #압축할 component의 수 지정\n",
        "\n",
        "X_train_lsa = svd.fit_transform(X_train_tfidf) ### ... 이 부분을 완성하시오\n",
        "X_test_lsa = svd.transform(X_test_tfidf)\n",
        "\n",
        "print('LSA Converted X shape:', X_train_lsa.shape)\n",
        "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_clf.fit(X_train_lsa, y_train) ### ... 이 부분을 완성하시오\n",
        "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_lsa, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_lsa, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4J-dk31PDQK",
        "outputId": "2c96d685-864e-428a-80ee-b59a6561cc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set score: 0.962\n",
            "#Test set score: 0.761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj3fEpEZcTpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac7b3a3-72dd-4dbc-f1d3-ecfad32a42aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA Converted X shape: (2034, 100)\n",
            "Sum of explained variance ratio: 0.209\n",
            "#Train set score: 0.810\n",
            "#Test set score: 0.745\n"
          ]
        }
      ],
      "source": [
        "# 100차원으로 압축해보기 -> 성능은 조금 떨어지지만 여전히 높은 성능의 수준이다.\n",
        "svd = TruncatedSVD(n_components=100, random_state=1) ### ... 이 부분을 완성하시오\n",
        "\n",
        "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
        "X_test_lsa = svd.transform(X_test_tfidf)\n",
        "\n",
        "print('LSA Converted X shape:', X_train_lsa.shape)\n",
        "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))\n",
        "\n",
        "LR_clf.fit(X_train_lsa, y_train)\n",
        "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_lsa, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_lsa, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWic08h5cTpJ"
      },
      "source": [
        "### 6.3.2 LSA를 이용한 의미 기반의 문서 간 유사도 계산\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문서1 : 저는 사과 좋아요\n",
        "문서2 : 저는 바나나 좋아요\n",
        "문서3 : 저는 바나나 좋아요 저는 바나나 좋아요\n",
        "\n",
        "띄어쓰기 기준 토큰화를 진행했다고 가정했을 때, 위의 세 문서에 대한 문서-단어 행렬\n",
        "\n",
        "| 문서 / 단어 | 저는 | 사과 | 좋아요 | 바나나 |\n",
        "|:--------:|:---:|:---:|:-----:|:----:|\n",
        "| **문서1**  |  1  |  1  |   1   |   0   |\n",
        "| **문서2**  |  1  |  0  |   1   |   1   |\n",
        "| **문서3**  |  2  |  0  |   2   |   2   |"
      ],
      "metadata": {
        "id": "rnPtaCVCnxGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy를 사용해서 코사인 유사도를 계산하는 방법\n",
        "* cos_sim(A, B) 함수를 구현하고 각 문서 벡터 간의 코사인 유사도를 계산"
      ],
      "metadata": {
        "id": "L1ZM_XP9n8is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B)) ### ... 이 부분을 완성하시오\n",
        "\n",
        "doc1 = np.array([0,1,1,1])\n",
        "doc2 = np.array([1,0,1,1])\n",
        "doc3 = np.array([2,0,2,2])\n",
        "\n",
        "print('문서 1과 문서2의 유사도 :',cos_sim(doc1, doc2))\n",
        "print('문서 1과 문서3의 유사도 :',cos_sim(doc1, doc3))\n",
        "print('문서 2와 문서3의 유사도 :',cos_sim(doc2, doc3))"
      ],
      "metadata": {
        "id": "ucsQAShInwSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb9db98-5cf0-4a40-f761-40acbf5bcdea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서 1과 문서2의 유사도 : 0.6666666666666667\n",
            "문서 1과 문서3의 유사도 : 0.6666666666666667\n",
            "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn의 cosine_similarity 를 이용하는 방법"
      ],
      "metadata": {
        "id": "Ns1Ha8kGoD0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# DTM 정의\n",
        "doc1 = np.array([[0,1,1,1]])\n",
        "doc2 = np.array([[1,0,1,1]])\n",
        "doc3 = np.array([[2,0,2,2]])\n",
        "\n",
        "# cosine_similarity를 사용하여 유사도 계산\n",
        "sim12 = cosine_similarity(doc1, doc2)\n",
        "sim13 = cosine_similarity(doc1, doc3)\n",
        "sim23 = cosine_similarity(doc2, doc3)\n",
        "\n",
        "print('문서 1과 문서2의 유사도 :', sim12[0][0])\n",
        "print('문서 1과 문서3의 유사도 :', sim13[0][0])\n",
        "print('문서 2와 문서3의 유사도 :', sim23[0][0])"
      ],
      "metadata": {
        "id": "GBQi58JCnwUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2610e54f-916d-4a8b-f7f6-b2dc64374932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서 1과 문서2의 유사도 : 0.6666666666666669\n",
            "문서 1과 문서3의 유사도 : 0.6666666666666669\n",
            "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSA 벡터 유사도 측정"
      ],
      "metadata": {
        "id": "l2EeedmClvLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgd0IR_lcTpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938b601a-6364-442d-d9d2-b6b00329da6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#사용된 전체 카테고리: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
            "#첫 문서의 카테고리: 1\n",
            "#첫 문서의 내용: Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "#Top 20 유사도(lsa):\n",
            " [1.0, 0.74, 0.74, 0.72, 0.7, 0.7, 0.69, 0.67, 0.66, 0.65, 0.65, 0.65, 0.63, 0.62, 0.62, 0.62, 0.57, 0.57, 0.55, 0.54]\n",
            "#Top 20 유사 뉴스의 인덱스(lsa):\n",
            " [   0 1957 1674  501 1995 1490  790 1902 1575 1209 1728  892 1892  998\n",
            " 1038 1826 1290 1089  867  151]\n",
            "#Top 20 유사 뉴스의 카테고리(lsa):\n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print('#사용된 전체 카테고리:', newsgroups_train.target_names)\n",
        "print('#첫 문서의 카테고리:', y_train[0])\n",
        "\n",
        "print('#첫 문서의 내용:', X_train[0])\n",
        "\n",
        "#변환된 count vector와 기존 값들과의 similarity 계산\n",
        "sim_result = cosine_similarity([X_train_lsa[0]], X_train_lsa) ### ... 이 부분을 완성하시오\n",
        "\n",
        "print(\"#Top 20 유사도(lsa):\\n\", sorted(sim_result[0].round(2), reverse=True)[:20])\n",
        "sim_index = (-sim_result[0]).argsort()[:20]\n",
        "print('#Top 20 유사 뉴스의 인덱스(lsa):\\n', sim_index)\n",
        "sim_labels = [y_train[i] for i in sim_index]\n",
        "print('#Top 20 유사 뉴스의 카테고리(lsa):\\n', sim_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[1957]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "KFHXqrajRJIP",
        "outputId": "b3a992a8-b14e-495b-c5b9-19135495183a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\nYou can include postscript epsi files in xfig (encapsulated postscript\\ninfo files). You can't actually edit the postscript file, but you're able\\nto draw over the postscript file.\\n\\nThere a eps to epsi converter: eps2epsi (perl program),\\n\\nSucces,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[1674]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "HXGdh-P6RYl7",
        "outputId": "38889c7f-f79d-4513-ee88-c199fd83df9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n    The gl2p1.lzh stuff under gfx/show on the Aminet sites includes a\\n    utility called pic2hl, that is a filter for HamLab that can handle\\n    the most commonly used kinds of .PIC and .CLP files.\\n\\n    The biggest problem is that the .CLP files don\\'t usually contain a\\n    palette, so you need to convert a .PIC with the right palette\\n    first (which creates a \"ram:picpal\" file), and then convert the\\n    .CLP files.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF 벡터 유사도 측정"
      ],
      "metadata": {
        "id": "6To4eJ5llsLt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZVBxkrzcTpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a2f5a8-4e4f-4352-9977-5a6865720274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Top 20 유사도(tfidf):\n",
            " [1.0, 0.3, 0.22, 0.21, 0.19, 0.19, 0.19, 0.17, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14]\n",
            "#Top 20 유사 뉴스의 인덱스(tfidf):\n",
            " [   0 1575 1892 1490  501 1290 1013  998 1636 1705 1995 1957 1664  651\n",
            " 1038  429 1089 1209 1728 1803]\n",
            "#Top 20 유사 뉴스의 카테고리(tfidf):\n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
        "\n",
        "# 유사도가 높은 순으로 정렬\n",
        "print(\"#Top 20 유사도(tfidf):\\n\", sorted(sim_result[0].round(2), reverse=True)[:20]) ### ... 이 부분을 완성하시오\n",
        "\n",
        "# 유사도가 높은 순으로 정렬 후, 해당 값의 index를 반환\n",
        "sim_index = (-sim_result[0]).argsort()[:20] ### ... 이 부분을 완성하시오\n",
        "print('#Top 20 유사 뉴스의 인덱스(tfidf):\\n', sim_index)\n",
        "sim_labels = [y_train[i] for i in sim_index]\n",
        "print('#Top 20 유사 뉴스의 카테고리(tfidf):\\n', sim_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-1 주차 수업 내용 -끝-\n",
        "\n"
      ],
      "metadata": {
        "id": "JzC4y3peu7oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [[실습 7-1-1]] 유사도를 이용한 영화 추천 시스템 구현하기: TF-IDF 벡터 vs LSA 벡터\n",
        "영화 소개, 제목, 평점 등이 있는 **'movies_metadata.csv'** 데이터 셋을 이용하여, 특정 영화와 가장 유사한 영화를 찾아 추천해주기\n",
        "\n",
        "* 영화 소개(overview)에 대한 내용을 각각 TF-IDF 벡터로도 나타내보고, LSA로도 나타내보기\n",
        "* 유사한 영화에 자기 자신을 포함할 수 있음. 가능한 경우, 이를 따로 처리해도 좋고 처리하지 않아도 됨\n",
        "* Dataset: https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### [제출 내용]\n",
        "\n",
        "1.   TF-IDF를 이용하여, 영화 소개(overview)의 내용이 가장 유사한 영화(title) 5개를 찾는 코드 작성\n",
        "    \n",
        "2.   LSA를 이용하여, 영화 소개(overview)의 내용이 가장 유사한 영화(title) 5개를 찾는 코드 작성\n",
        "3.   TF-IDF와 LSA의 결과 비교 설명. LSA가 의미를 더 잘 찾는 것 같은지? 자신에게는 TF-IDF와 LSA 중 어떤 것이 더 마음에 드는 방법이었는지 결론을 내려보기\n",
        "    * 유사도, 영화 소개의 내용, average_vote (평점) 등을 참고하여 비교해 보시오.\n",
        "\n",
        "\n",
        "### [참고 코드]\n",
        "* **참고용**으로 사용하시면 됩니다. 더 편한 방법이 있다면 해당 방법으로 작성하셔도 좋습니다.\n",
        "* 참고 코드는 0번째 영화 & TF-IDF에 대해서만 작성되어 있음\n",
        "    * 0번째 영화가 아닌 다른 n번째 영화를 선택하여 비교해보아도 좋습니다.\n",
        "    * **(주의!)** LSA에 대한 코드를 추가 작성해야 합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "df = pd.read_csv('./movies_metadata.csv', encoding='utf-8', low_memory=False)\n",
        "df.head(5)\n",
        "```\n",
        "\n",
        "```\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 평점이 8점 이상인 영화 중에서 추천\n",
        "sampled_df = df[df['vote_average'] >= 8].reset_index(drop=True)\n",
        "sampled_df.shape\n",
        "```\n",
        "\n",
        "```\n",
        "# overview에 빈 값이 있는 경우, ''로 채우기\n",
        "sampled_df['overview'] = sampled_df['overview'].fillna('')\n",
        "```\n",
        "\n",
        "```\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sampled_df.overview, sampled_df.title, random_state=0)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "```\n",
        "```\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"0번째 영화 제목\\n\", y_train[0])\n",
        "print(\"0번째 영화 소개 내용\\n\", X_train[0])\n",
        "\n",
        "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
        "\n",
        "print(\"#Top 5 유사도(tfidf):\\n\", sorted(sim_result[0].round(2), reverse=True)[:5])\n",
        "sim_index = (-sim_result[0]).argsort()[:5]\n",
        "```\n",
        "```\n",
        "result_df = pd.DataFrame({\n",
        "    '유사도': sorted(sim_result[0].round(2), reverse=True)[:5],\n",
        "    '인덱스': sim_index,\n",
        "    '제목': [sampled_df.title[i] for i in sim_index],\n",
        "    '영화 소개': [sampled_df.overview[i] for i in sim_index],\n",
        "    '평점': [sampled_df.vote_average[i] for i in sim_index]\n",
        "})\n",
        "\n",
        "result_df\n",
        "```\n",
        "```\n",
        "X_train_tfidf.shape\n",
        "```\n",
        "```\n",
        "print('TF-IDF 기반으로 계산한 결과 추천하는 영화는: ', [sampled_df.title[i] for i in sim_index][1:])\n",
        "```\n",
        "* ### 위의 참고 코드를 복사 붙여넣기하여 시작해보시면 도움이 될 것 같습니다.\n",
        "* ### 아래에 코드 또는 텍스트를 추가하여 작성하시기 바랍니다."
      ],
      "metadata": {
        "id": "IFkQNW24z-eI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E4kXNz3cbe00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./movies_metadata.csv', encoding='utf-8', low_memory=False)\n",
        "df.head(5)\n",
        "#df.shape -> (45466, 24)"
      ],
      "metadata": {
        "id": "dbNAqdw6bblL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "fb734762-1100-4e67-fc24-9621244854b9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   adult                              belongs_to_collection    budget  \\\n",
              "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
              "1  False                                                NaN  65000000   \n",
              "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
              "3  False                                                NaN  16000000   \n",
              "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
              "\n",
              "                                              genres  \\\n",
              "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
              "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
              "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
              "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
              "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
              "\n",
              "                               homepage     id    imdb_id original_language  \\\n",
              "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
              "1                                   NaN   8844  tt0113497                en   \n",
              "2                                   NaN  15602  tt0113228                en   \n",
              "3                                   NaN  31357  tt0114885                en   \n",
              "4                                   NaN  11862  tt0113041                en   \n",
              "\n",
              "                original_title  \\\n",
              "0                    Toy Story   \n",
              "1                      Jumanji   \n",
              "2             Grumpier Old Men   \n",
              "3            Waiting to Exhale   \n",
              "4  Father of the Bride Part II   \n",
              "\n",
              "                                            overview  ... release_date  \\\n",
              "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
              "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
              "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
              "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
              "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
              "\n",
              "       revenue runtime                                   spoken_languages  \\\n",
              "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
              "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "\n",
              "     status                                            tagline  \\\n",
              "0  Released                                                NaN   \n",
              "1  Released          Roll the dice and unleash the excitement!   \n",
              "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
              "3  Released  Friends are the people who let you be yourself...   \n",
              "4  Released  Just When His World Is Back To Normal... He's ...   \n",
              "\n",
              "                         title  video vote_average vote_count  \n",
              "0                    Toy Story  False          7.7     5415.0  \n",
              "1                      Jumanji  False          6.9     2413.0  \n",
              "2             Grumpier Old Men  False          6.5       92.0  \n",
              "3            Waiting to Exhale  False          6.1       34.0  \n",
              "4  Father of the Bride Part II  False          5.7      173.0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e97ca179-04fd-4a0c-a511-6f1f165abc01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>adult</th>\n",
              "      <th>belongs_to_collection</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>id</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>...</th>\n",
              "      <th>release_date</th>\n",
              "      <th>revenue</th>\n",
              "      <th>runtime</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>video</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
              "      <td>30000000</td>\n",
              "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
              "      <td>http://toystory.disney.com/toy-story</td>\n",
              "      <td>862</td>\n",
              "      <td>tt0114709</td>\n",
              "      <td>en</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>...</td>\n",
              "      <td>1995-10-30</td>\n",
              "      <td>373554033.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>False</td>\n",
              "      <td>7.7</td>\n",
              "      <td>5415.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65000000</td>\n",
              "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8844</td>\n",
              "      <td>tt0113497</td>\n",
              "      <td>en</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>...</td>\n",
              "      <td>1995-12-15</td>\n",
              "      <td>262797249.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
              "      <td>Released</td>\n",
              "      <td>Roll the dice and unleash the excitement!</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>False</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2413.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15602</td>\n",
              "      <td>tt0113228</td>\n",
              "      <td>en</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>...</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>False</td>\n",
              "      <td>6.5</td>\n",
              "      <td>92.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16000000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31357</td>\n",
              "      <td>tt0114885</td>\n",
              "      <td>en</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
              "      <td>...</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>81452156.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Friends are the people who let you be yourself...</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>False</td>\n",
              "      <td>6.1</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11862</td>\n",
              "      <td>tt0113041</td>\n",
              "      <td>en</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>...</td>\n",
              "      <td>1995-02-10</td>\n",
              "      <td>76578911.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>False</td>\n",
              "      <td>5.7</td>\n",
              "      <td>173.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e97ca179-04fd-4a0c-a511-6f1f165abc01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e97ca179-04fd-4a0c-a511-6f1f165abc01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e97ca179-04fd-4a0c-a511-6f1f165abc01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67c5ddea-110d-44c1-bfef-eba3611902aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67c5ddea-110d-44c1-bfef-eba3611902aa')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67c5ddea-110d-44c1-bfef-eba3611902aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 평점이 8점 이상인 영화 중에서 추천\n",
        "sampled_df = df[df['vote_average'] >= 8].reset_index(drop=True)\n",
        "print(sampled_df.shape)\n",
        "\n",
        "# overview에 빈 값이 있는 경우, ''로 채우기\n",
        "sampled_df['overview'] = sampled_df['overview'].fillna('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4aMrmcnTb_v",
        "outputId": "286958f2-608c-48ba-bc0c-d885ace31a8c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1895, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############ !!! tfdif로 유사한 영화 5개 출력하기 !!! #############\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sampled_df.overview, sampled_df.title, random_state=0)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "AQ1YhFocTsiO"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"0번째 영화 제목\\n\", y_train[0])\n",
        "print(\"0번째 영화 소개 내용\\n\", X_train[0])\n",
        "\n",
        "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
        "\n",
        "print(\"#Top 5 유사도(tfidf):\\n\", sorted(sim_result[0].round(2), reverse=True)[:5])\n",
        "sim_index = (-sim_result[0]).argsort()[:5]\n",
        "\n",
        "result_df = pd.DataFrame({\n",
        "    '유사도': sorted(sim_result[0].round(2), reverse=True)[:5],\n",
        "    '인덱스': sim_index,\n",
        "    '제목': [sampled_df.title[i] for i in sim_index],\n",
        "    '영화 소개': [sampled_df.overview[i] for i in sim_index],\n",
        "    '평점': [sampled_df.vote_average[i] for i in sim_index]\n",
        "})\n",
        "\n",
        "result_df\n",
        "X_train_tfidf.shape\n",
        "\n",
        "print('TF-IDF 기반으로 계산한 결과 추천하는 영화는: ', [sampled_df.title[i] for i in sim_index][1:])\n",
        "print(sim_index[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeXoPenyVAoR",
        "outputId": "d0a497d5-7422-4d19-de51-e14cf06c6226"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0번째 영화 제목\n",
            " Se7en\n",
            "0번째 영화 소개 내용\n",
            " Two homicide detectives are on a desperate hunt for a serial killer whose crimes are based on the \"seven deadly sins\" in this dark and haunting film that takes viewers from the tortured remains of one victim to the next. The seasoned Det. Sommerset researches each sin in an effort to get inside the killer's mind, while his novice partner, Mills, scoffs at his efforts to unravel the case.\n",
            "#Top 5 유사도(tfidf):\n",
            " [1.0, 0.27, 0.26, 0.23, 0.23]\n",
            "TF-IDF 기반으로 계산한 결과 추천하는 영화는:  ['Pin Boy', 'Karachi se Lahore', 'Houston, We Have a Problem!', 'Pudhupettai']\n",
            "[1301 1130 1399 1003]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.overview[1130]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fmA8hCONbBCp",
        "outputId": "140be085-f31f-4881-ebc9-b2e97dc2338d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A road trip from Karachi to Lahore where 5 friends discover themselves and the country amidst getting to their destination.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Two homicide detectives are on a desperate hunt for a serial killer whose crimes are based on the \"seven deadly sins\" in this dark and haunting film that takes viewers from the tortured remains of one victim to the next. The seasoned Det. Sommerset researches each sin in an effort to get inside the killer's mind, while his novice partner, Mills, scoffs at his efforts to unravel the case.\n"
      ],
      "metadata": {
        "id": "LJRZhgIlbU6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############ !!! LSA로 유사한 영화 5개 출력하기 !!! #############\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=100, random_state=7) #압축할 component의 수 지정\n",
        "\n",
        "X_train_lsa = svd.fit_transform(X_train_tfidf) ### ... 이 부분을 완성하시오\n",
        "X_test_lsa = svd.transform(X_test_tfidf)\n",
        "\n",
        "print('LSA Converted X shape:', X_train_lsa.shape)\n",
        "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ2g6IbTdr5Q",
        "outputId": "805df119-0f19-46e0-863f-fc35b5f112ac"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA Converted X shape: (1421, 100)\n",
            "Sum of explained variance ratio: 0.301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"0번째 영화 제목\\n\", y_train[0])\n",
        "print(\"0번째 영화 소개 내용\\n\", X_train[0])\n",
        "\n",
        "#변환된 count vector와 기존 값들과의 similarity 계산\n",
        "sim_result = cosine_similarity([X_train_lsa[0]], X_train_lsa)\n",
        "\n",
        "print(\"#Top 5 유사도(lsa):\\n\", sorted(sim_result[0].round(2), reverse=True)[:5])\n",
        "sim_index = (-sim_result[0]).argsort()[:5]\n",
        "\n",
        "result_df = pd.DataFrame({\n",
        "    '유사도': sorted(sim_result[0].round(2), reverse=True)[:5],\n",
        "    '인덱스': sim_index,\n",
        "    '제목': [sampled_df.title[i] for i in sim_index],\n",
        "    '영화 소개': [sampled_df.overview[i] for i in sim_index],\n",
        "    '평점': [sampled_df.vote_average[i] for i in sim_index]\n",
        "})\n",
        "\n",
        "result_df\n",
        "X_train_tfidf.shape\n",
        "\n",
        "print('TF-IDF 기반으로 계산한 결과 추천하는 영화는: ', [sampled_df.title[i] for i in sim_index][1:])\n",
        "print(sim_index[1:])"
      ],
      "metadata": {
        "id": "RBTBe_sjeuA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f334237f-31a2-4dbb-8876-23163f311ee9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0번째 영화 제목\n",
            " Se7en\n",
            "0번째 영화 소개 내용\n",
            " Two homicide detectives are on a desperate hunt for a serial killer whose crimes are based on the \"seven deadly sins\" in this dark and haunting film that takes viewers from the tortured remains of one victim to the next. The seasoned Det. Sommerset researches each sin in an effort to get inside the killer's mind, while his novice partner, Mills, scoffs at his efforts to unravel the case.\n",
            "#Top 5 유사도(lsa):\n",
            " [1.0, 0.65, 0.61, 0.6, 0.55]\n",
            "TF-IDF 기반으로 계산한 결과 추천하는 영화는:  ['Pin Boy', 'The Dream Team', 'Houston, We Have a Problem!', 'One Last Hug']\n",
            "[1301 1044 1399  914]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.overview[1044]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "fh56F3jagqdh",
        "outputId": "9bccb504-22f0-4a6a-c144-b97484abe47f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The world had rarely seen a frenzy as the one the Dream Team created when it arrived in Barcelona, Spain, in July 1992. The Dream Team featured 11 future Naismith Memorial Basketball Hall of Fame players and three future Hall of Famers on the coaching staff, including head coach Chuck Daly.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TF-IDF와 LSA의 결과 비교 설명. LSA가 의미를 더 잘 찾는 것 같은지? 자신에게는 TF-IDF와 LSA 중 어떤 것이 더 마음에 드는 방법이었는지 결론을 내려보기\n",
        "\n",
        "* 유사도, 영화 소개의 내용, average_vote (평점) 등을 참고하여 비교해 보시오."
      ],
      "metadata": {
        "id": "NcMosXrSg7RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0번째 영화로 tfidf와 LSA 결과 비교 (n_components=100으로 설정)\n",
        "* 0번째 영화 소개 내용\n",
        " Two homicide detectives are on a desperate hunt for a serial killer whose crimes are based on the \"seven deadly sins\" in this dark and haunting film that takes viewers from the tortured remains of one victim to the next. The seasoned Det. Sommerset researches each sin in an effort to get inside the killer's mind, while his novice partner, Mills, scoffs at his efforts to unravel the case.\n",
        "\n",
        "* 유사도 비교\n",
        "> tfidf Top 5 유사도(tfidf):\n",
        " [1.0, 0.27, 0.26, 0.23, 0.23]\n",
        "\n",
        "  > LSA Top 5 유사도(lsa):\n",
        " [1.0, 0.65, 0.61, 0.6, 0.55]\n",
        "\n",
        "* 유사도 높은 영화 overview 비교\n",
        "> (tfidf) sampled_df.overview[1130] A road trip from Karachi to Lahore where 5 friends discover themselves and the country amidst getting to their destination.\n",
        "\n",
        "  > (LSA) sampled_df.overview[1044] The world had rarely seen a frenzy as the one the Dream Team created when it arrived in Barcelona, Spain, in July 1992. The Dream Team featured 11 future Naismith Memorial Basketball Hall of Fame players and three future Hall of Famers on the coaching staff, including head coach Chuck Daly.\n",
        "\n",
        "* tfidf 와 LSA의 유사도로 보면 LSA의 유사도가 훨씬 높은 것을 알 수 있다. 영화 내용 소개로 보았을 때, LSA가 차원 수를 100으로 줄였음에도 의미를 더 잘 찾은 것 같고, 더 빨라서 좋았다."
      ],
      "metadata": {
        "id": "wbGHnmjhhBkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Dh5p1dNZ5gHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [파일] -> [다운로드] -> [.ipynb 다운로드]\n",
        "# 제출 후 **구글 계정 로그아웃** 잘 하시기 바랍니다."
      ],
      "metadata": {
        "id": "esH2v6SMu-gg"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}